{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS': 30,\n",
    "    'LEARNING_RATE':1e-2,\n",
    "    'BATCH_SIZE':256,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "    - 1. 결측치 처리\n",
    "\n",
    "    - 2. Train / Validation 분할\n",
    "\n",
    "    - 3. Data label-encoding, scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['COMPONENT_ARBITRARY', 'YEAR']\n",
    "# Inference(실제 진단 환경)에 사용하는 컬럼\n",
    "test_stage_features = ['COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR' , 'ANONYMOUS_2', 'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = train.drop(['ID', 'Y_LABEL'], axis = 1)\n",
    "all_y = train['Y_LABEL']\n",
    "\n",
    "test = test.drop(['ID'], axis = 1)\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(all_X, all_y, test_size=0.2, random_state=CFG['SEED'], stratify=all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(value):\n",
    "    return value.values.reshape(-1, 1)\n",
    "\n",
    "for col in train_X.columns:\n",
    "    if col not in categorical_features:\n",
    "        scaler = StandardScaler()\n",
    "        train_X[col] = scaler.fit_transform(get_values(train_X[col]))\n",
    "        val_X[col] = scaler.transform(get_values(val_X[col]))\n",
    "        if col in test.columns:\n",
    "            test[col] = scaler.transform(get_values(test[col]))\n",
    "            \n",
    "le = LabelEncoder()\n",
    "for col in categorical_features:    \n",
    "    train_X[col] = le.fit_transform(train_X[col])\n",
    "    val_X[col] = le.transform(val_X[col])\n",
    "    if col in test.columns:\n",
    "        test[col] = le.transform(test[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_X, data_y, distillation=False):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.data_X = data_X\n",
    "        self.data_y = data_y\n",
    "        self.distillation = distillation\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.distillation:\n",
    "            # 지식 증류 학습 시\n",
    "            teacher_X = torch.Tensor(self.data_X.iloc[index])\n",
    "            student_X = torch.Tensor(self.data_X[test_stage_features].iloc[index])\n",
    "            y = self.data_y.values[index]\n",
    "            return teacher_X, student_X, y\n",
    "        else:\n",
    "            if self.data_y is None:\n",
    "                test_X = torch.Tensor(self.data_X.iloc[index])\n",
    "                return test_X\n",
    "            else:\n",
    "                teacher_X = torch.Tensor(self.data_X.iloc[index])\n",
    "                y = self.data_y.values[index]\n",
    "                return teacher_X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_X, train_y, False)\n",
    "val_dataset = CustomDataset(val_X, val_y, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Teacher, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=52, out_features=256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=256, out_features=1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=256, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher Train / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    for epoch in range(CFG[\"EPOCHS\"]):\n",
    "        train_loss = []\n",
    "  \n",
    "        model.train()\n",
    "        for X, y in tqdm(train_loader):\n",
    "            X = X.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            \n",
    "            loss = criterion(y_pred, y.reshape(-1, 1))\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        val_loss, val_score = validation_teacher(model, val_loader, criterion, device)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{np.mean(train_loss) :.5f}] Val Loss : [{np.mean(val_loss) :.5f}] Val F1 Score : [{val_score:.5f}]')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_score)\n",
    "            \n",
    "        if best_score < val_score:\n",
    "            best_model = model\n",
    "            best_score = val_score\n",
    "        \n",
    "    return best_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def competition_metric(true, pred):\n",
    "    return f1_score(true, pred, average=\"macro\")\n",
    "\n",
    "def validation_teacher(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    threshold = 0.35\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(val_loader):\n",
    "            X = X.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = model(X.to(device))\n",
    "            \n",
    "            loss = criterion(model_pred, y.reshape(-1, 1))\n",
    "            val_loss.append(loss.item())      \n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')  \n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        pred_labels = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "        val_f1 = competition_metric(true_labels, pred_labels)\n",
    "    return val_loss, val_f1   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run (Teacher Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:03<00:00, 13.62it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 28.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.26777] Val Loss : [0.24944] Val F1 Score : [0.74427]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.90it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 30.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.20180] Val Loss : [0.25914] Val F1 Score : [0.77812]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 18.29it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 32.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.20208] Val Loss : [0.28410] Val F1 Score : [0.77435]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 18.88it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 34.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.18748] Val Loss : [0.26709] Val F1 Score : [0.77670]\n",
      "Epoch 00004: reducing learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.89it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 32.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.16492] Val Loss : [0.28467] Val F1 Score : [0.78601]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.61it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 32.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.16954] Val Loss : [0.27747] Val F1 Score : [0.79584]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.23it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 33.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.16682] Val Loss : [0.26679] Val F1 Score : [0.79515]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.27it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 33.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.15152] Val Loss : [0.24449] Val F1 Score : [0.78952]\n",
      "Epoch 00008: reducing learning rate of group 0 to 2.5000e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 19.35it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 31.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.14315] Val Loss : [0.28120] Val F1 Score : [0.78789]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 18.54it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 32.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.14376] Val Loss : [0.32296] Val F1 Score : [0.78695]\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.2500e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 16.96it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 26.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.14909] Val Loss : [0.26250] Val F1 Score : [0.79107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 18.22it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 32.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.13444] Val Loss : [0.29889] Val F1 Score : [0.79469]\n",
      "Epoch 00012: reducing learning rate of group 0 to 6.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.84it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 32.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.13066] Val Loss : [0.31324] Val F1 Score : [0.79127]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.98it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 34.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.12989] Val Loss : [0.30327] Val F1 Score : [0.78987]\n",
      "Epoch 00014: reducing learning rate of group 0 to 3.1250e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.85it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 33.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.12673] Val Loss : [0.30412] Val F1 Score : [0.78377]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 19.01it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 28.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [0.12693] Val Loss : [0.31454] Val F1 Score : [0.78190]\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.5625e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.06it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 32.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [0.13438] Val Loss : [0.33049] Val F1 Score : [0.79127]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.48it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 30.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [0.12378] Val Loss : [0.32051] Val F1 Score : [0.79383]\n",
      "Epoch 00018: reducing learning rate of group 0 to 7.8125e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.05it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 34.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [0.12366] Val Loss : [0.31124] Val F1 Score : [0.78978]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 18.15it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 31.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [0.12307] Val Loss : [0.31035] Val F1 Score : [0.78772]\n",
      "Epoch 00020: reducing learning rate of group 0 to 3.9063e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.65it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 32.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [0.12687] Val Loss : [0.32082] Val F1 Score : [0.78515]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 18.07it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 29.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [0.12107] Val Loss : [0.32786] Val F1 Score : [0.79724]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 19.84it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 31.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [0.12664] Val Loss : [0.32427] Val F1 Score : [0.79052]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 19.25it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 33.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [0.13284] Val Loss : [0.31424] Val F1 Score : [0.78624]\n",
      "Epoch 00024: reducing learning rate of group 0 to 1.9531e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 16.93it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 30.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [0.12980] Val Loss : [0.32444] Val F1 Score : [0.78611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 17.52it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 34.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [0.12429] Val Loss : [0.32838] Val F1 Score : [0.77954]\n",
      "Epoch 00026: reducing learning rate of group 0 to 9.7656e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 16.62it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 32.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Train Loss : [0.12246] Val Loss : [0.29875] Val F1 Score : [0.78707]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 16.34it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Train Loss : [0.13857] Val Loss : [0.31126] Val F1 Score : [0.78914]\n",
      "Epoch 00028: reducing learning rate of group 0 to 4.8828e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 16.90it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 33.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Train Loss : [0.12161] Val Loss : [0.31570] Val F1 Score : [0.78659]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 18.13it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 33.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Train Loss : [0.13114] Val Loss : [0.32325] Val F1 Score : [0.78082]\n",
      "Epoch 00030: reducing learning rate of group 0 to 2.4414e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Teacher()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1, threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "teacher_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Student, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=18, out_features=128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=512, out_features=128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Knowledge distillation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation(student_logits, labels, teacher_logits, alpha):\n",
    "    distillation_loss = nn.BCELoss()(student_logits, teacher_logits)\n",
    "    student_loss = nn.BCELoss()(student_logits, labels.reshape(-1, 1))\n",
    "    return alpha * student_loss + (1-alpha) * distillation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distill_loss(output, target, teacher_output, loss_fn=distillation, opt=optimizer):\n",
    "    loss_b = loss_fn(output, target, teacher_output, alpha=0.1)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss_b.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss_b.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Train / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_train(s_model, t_model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    s_model.to(device)\n",
    "    t_model.to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(CFG[\"EPOCHS\"]):\n",
    "        train_loss = []\n",
    "        s_model.train()\n",
    "        t_model.eval()\n",
    "        \n",
    "        for X_t, X_s, y in tqdm(train_loader):\n",
    "            X_t = X_t.float().to(device)\n",
    "            X_s = X_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = s_model(X_s)\n",
    "            with torch.no_grad():\n",
    "                teacher_output = t_model(X_t)\n",
    "                \n",
    "            loss_b = distill_loss(output, y, teacher_output, loss_fn=distillation, opt=optimizer)\n",
    "\n",
    "            train_loss.append(loss_b)\n",
    "\n",
    "        val_loss, val_score = validation_student(s_model, t_model, val_loader, distill_loss, device)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{np.mean(train_loss) :.5f}] Val Loss : [{np.mean(val_loss) :.5f}] Val F1 Score : [{val_score:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_score)\n",
    "            \n",
    "        if best_score < val_score:\n",
    "            best_model = s_model\n",
    "            best_score = val_score\n",
    "        \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_student(s_model, t_model, val_loader, criterion, device):\n",
    "    s_model.eval()\n",
    "    t_model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    threshold = 0.35\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_t, X_s, y in tqdm(val_loader):\n",
    "            X_t = X_t.float().to(device)\n",
    "            X_s = X_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = s_model(X_s)\n",
    "            teacher_output = t_model(X_t)\n",
    "            \n",
    "            loss_b = distill_loss(model_pred, y, teacher_output, loss_fn=distillation, opt=None)\n",
    "            val_loss.append(loss_b)\n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        pred_labels = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "        val_f1 = competition_metric(true_labels, pred_labels)\n",
    "    return val_loss, val_f1    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run (Student Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_X, train_y, True)\n",
    "val_dataset = CustomDataset(val_X, val_y, True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.49it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.33680] Val Loss : [0.29234] Val F1 Score : [0.47680]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.59it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.30735] Val Loss : [0.29715] Val F1 Score : [0.49009]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.55it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.30369] Val Loss : [0.28813] Val F1 Score : [0.49164]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.45it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.29390] Val Loss : [0.28704] Val F1 Score : [0.50881]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.44it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.29186] Val Loss : [0.28839] Val F1 Score : [0.49565]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.52it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.29111] Val Loss : [0.28976] Val F1 Score : [0.49712]\n",
      "Epoch 00006: reducing learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.55it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.28573] Val Loss : [0.28625] Val F1 Score : [0.51450]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:07<00:00,  6.36it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.28494] Val Loss : [0.29003] Val F1 Score : [0.49133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.98it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.28617] Val Loss : [0.28865] Val F1 Score : [0.51532]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.13it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.28565] Val Loss : [0.28772] Val F1 Score : [0.49892]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.03it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.28498] Val Loss : [0.28952] Val F1 Score : [0.50018]\n",
      "Epoch 00011: reducing learning rate of group 0 to 2.5000e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.05it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.28193] Val Loss : [0.28551] Val F1 Score : [0.50834]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.09it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.28200] Val Loss : [0.28801] Val F1 Score : [0.51579]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.10it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.28420] Val Loss : [0.28969] Val F1 Score : [0.51197]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.55it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.28776] Val Loss : [0.28856] Val F1 Score : [0.51333]\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.2500e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.89it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [0.28042] Val Loss : [0.28725] Val F1 Score : [0.50706]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.91it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [0.28524] Val Loss : [0.28762] Val F1 Score : [0.51380]\n",
      "Epoch 00017: reducing learning rate of group 0 to 6.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.88it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [0.28318] Val Loss : [0.28496] Val F1 Score : [0.51603]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.13it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [0.27935] Val Loss : [0.28836] Val F1 Score : [0.51865]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.91it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [0.27649] Val Loss : [0.28764] Val F1 Score : [0.51816]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.62it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [0.27700] Val Loss : [0.28901] Val F1 Score : [0.52418]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.45it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [0.27737] Val Loss : [0.28963] Val F1 Score : [0.52094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.89it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [0.27668] Val Loss : [0.28997] Val F1 Score : [0.52085]\n",
      "Epoch 00023: reducing learning rate of group 0 to 3.1250e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:07<00:00,  6.32it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [0.27965] Val Loss : [0.28985] Val F1 Score : [0.52068]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.01it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [0.27827] Val Loss : [0.29014] Val F1 Score : [0.52119]\n",
      "Epoch 00025: reducing learning rate of group 0 to 1.5625e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.17it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [0.28006] Val Loss : [0.28974] Val F1 Score : [0.51919]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.13it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Train Loss : [0.28202] Val Loss : [0.29051] Val F1 Score : [0.51993]\n",
      "Epoch 00027: reducing learning rate of group 0 to 7.8125e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.07it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Train Loss : [0.27927] Val Loss : [0.29158] Val F1 Score : [0.51623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  6.98it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Train Loss : [0.27555] Val Loss : [0.29043] Val F1 Score : [0.52211]\n",
      "Epoch 00029: reducing learning rate of group 0 to 3.9063e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.18it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Train Loss : [0.27808] Val Loss : [0.29737] Val F1 Score : [0.51078]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "student_model = Student()\n",
    "student_model.eval()\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1, threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "best_student_model = student_train(student_model, teacher_model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Inference Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_threshold(model, val_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    thresholds = [0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    best_score = 0\n",
    "    best_thr = None\n",
    "    with torch.no_grad():\n",
    "        for _, x_s, y in tqdm(iter(val_loader)):\n",
    "            x_s = x_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = model(x_s)\n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            pred_labels_thr = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "            score_thr = competition_metric(true_labels, pred_labels_thr)\n",
    "            if best_score < score_thr:\n",
    "                best_score = score_thr\n",
    "                best_thr = threshold\n",
    "    return best_thr, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold : [0.2], Score : [0.53526]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_threshold, best_score = choose_threshold(best_student_model, val_loader, device)\n",
    "print(f'Best Threshold : [{best_threshold}], Score : [{best_score:.5f}]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = CustomDataset(test, None, False)\n",
    "test_loaders = DataLoader(test_datasets, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, threshold, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    test_predict = []\n",
    "    with torch.no_grad():\n",
    "        for x in tqdm(test_loader):\n",
    "            x = x.float().to(device)\n",
    "            model_pred = model(x)\n",
    "\n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            test_predict += model_pred\n",
    "        \n",
    "    test_predict = np.where(np.array(test_predict) > threshold, 1, 0)\n",
    "    print('Done.')\n",
    "    return test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 44.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "preds = inference(best_student_model, test_loaders, best_threshold, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Y_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Y_LABEL\n",
       "0  TEST_0000        0\n",
       "1  TEST_0001        0\n",
       "2  TEST_0002        0\n",
       "3  TEST_0003        0\n",
       "4  TEST_0004        1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['Y_LABEL'] = preds\n",
    "submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
